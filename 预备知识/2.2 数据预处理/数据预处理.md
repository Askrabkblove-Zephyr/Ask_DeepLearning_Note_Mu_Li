## 2.2. 数据预处理

### 2.2.1. 读取数据集

```python
import os
# 如果文件夹已经存在，不报错
# join 拼接路径
os.makedirs(os.path.join('..', 'data'), exist_ok=True)
data_file = os.path.join('..', 'data', 'house_tiny.csv')
# with 上下文管理器
with open(data_file, 'w') as f:
    f.write('NumRooms,Alley,Price\n')  # 列名
    f.write('NA,Pave,127500\n')  # 每行表示一个数据样本
    f.write('2,NA,106000\n')
    f.write('4,NA,178100\n')
    f.write('NA,NA,140000\n')
    
# 如果没有安装pandas，只需取消对以下行的注释来安装pandas
# !pip install pandas
import pandas as pd

data = pd.read_csv(data_file)
print(data)
```

### 2.2.2. 处理缺失值

代码勘误，要想只修改NumRooms的值

```python
# iloc下标索引
# [:, 0:2] 获取全部行，0到1列（左闭右开）
# [:, 2] 获取全部行，第二列
inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]
# 只填充NumRooms列的缺失值，保留其他列的原值
inputs['NumRooms'] = inputs['NumRooms'].fillna(inputs['NumRooms'].mean())
print('inputs = \n', inputs)
print('outputs = \n', outputs)
```

```python
# 非数值类型才进行独热编码
# 独热编码将离散的分类标签转换成二进制向量
# 离散分类就是类别独立，不存在大小，前后等关系
# dummy_na=True 对缺失值创建单独的虚拟变量列
print(inputs)
# 如果dummy_na=True 和 False值相同有可能就是因为缺失值被填充了，或者就没有NAN值
inputs = pd.get_dummies(inputs, dummy_na=True)
print(inputs)
```

### 2.2.3. 转换为张量格式

```python
import torch

X = torch.tensor(inputs.to_numpy(dtype=float))
y = torch.tensor(outputs.to_numpy(dtype=float))
X, y
```

### 2.2.4. 小结

- `pandas`软件包是Python中常用的数据分析工具中，`pandas`可以与张量兼容。
- 用`pandas`处理缺失的数据时，我们可根据情况选择用插值法和删除法。

### 2.2.5. 练习

创建包含更多行和列的原始数据集。

1. 删除缺失值最多的列。
2. 将预处理后的数据集转换为张量格式。

```python
import pandas as pd
import numpy as np
import torch

# 设置随机种子以便复现
np.random.seed(42)

# 1. 创建包含更多行和列的原始数据集
def create_large_dataset(n_samples=100, n_features=15):
    """
    创建包含多种数据类型和缺失值的数据集
    """
    np.random.seed(42)

    # 创建特征
    data = {}

    # 数值型特征
    data['年龄'] = np.random.randint(18, 65, n_samples).astype(float)
    data['收入'] = np.random.normal(50000, 15000, n_samples).astype(float)
    data['工作经验'] = np.random.randint(0, 40, n_samples).astype(float)
    data['信用分数'] = np.random.randint(300, 850, n_samples).astype(float)

    # 添加缺失值到数值型特征（随机10-30%缺失）
    for col in ['年龄', '收入', '工作经验', '信用分数']:
        mask = np.random.random(n_samples) < 0.2  # 20%缺失
        data[col] = np.where(mask, np.nan, data[col])

    # 分类特征 - 正确使用None而不是np.nan
    # choice是 NumPy 中的一个非常重要的随机抽样函数
    # np.random.choice() 从一个给定的数组中随机选择元素。
    # np.random.choice(a, size=None, replace=True, p=None)
    # a	抽样的数组或整数	['A','B','C'] 或 5
    # size	输出形状	3, (2,3), None
    # replace	是否放回	True（可重复）或 False（不重复）
    # p	概率分布	[0.1, 0.2, 0.7]
    data['教育程度'] = np.random.choice(['高中', '本科', '硕士', '博士', None],
                                     n_samples, p=[0.3, 0.4, 0.2, 0.05, 0.05])
    data['职业'] = np.random.choice(['工程师', '医生', '教师', '销售', '其他', None],
                                n_samples, p=[0.25, 0.2, 0.15, 0.2, 0.15, 0.05])
    data['婚姻状况'] = np.random.choice(['单身', '已婚', '离异', None],
                                   n_samples, p=[0.4, 0.4, 0.15, 0.05])
    data['城市'] = np.random.choice(['北京', '上海', '广州', '深圳', '其他', None],
                                n_samples, p=[0.25, 0.25, 0.2, 0.2, 0.05, 0.05])

    # 布尔特征 - 使用None而不是np.nan
    data['有车'] = np.random.choice([True, False, None], n_samples, p=[0.6, 0.35, 0.05])
    data['有房'] = np.random.choice([True, False, None], n_samples, p=[0.5, 0.45, 0.05])

    # 目标变量（假设是贷款审批结果）
    data['贷款批准'] = np.random.choice([0, 1], n_samples, p=[0.3, 0.7])

    # 创建一些有高缺失率的列 - 分别处理数值和字符串类型
    # 数值列使用np.nan
    data['高缺失率列1'] = np.where(np.random.random(n_samples) < 0.8,
                                  np.nan,
                                  np.random.randint(1, 100, n_samples).astype(float))

    # 字符串列使用None
    high_missing2_values = []
    for _ in range(n_samples):
        if np.random.random() < 0.75:
            high_missing2_values.append(None)  # 使用None而不是np.nan
        else:
            high_missing2_values.append(np.random.choice(['A', 'B', 'C']))
    data['高缺失率列2'] = high_missing2_values

    # 数值列
    data['高缺失率列3'] = np.where(np.random.random(n_samples) < 0.85,
                                  np.nan,
                                  np.random.normal(0, 1, n_samples))

    # 创建DataFrame
    df = pd.DataFrame(data)

    # 添加一些完全空的行和列 - 使用np.nan对于数值列
    df['完全缺失列'] = np.nan

    # 最后5行全部为NaN
    df.loc[95:99] = np.nan

    return df

# 创建数据集
print("=== 1. 创建原始数据集 ===")
original_data = create_large_dataset(n_samples=100, n_features=15)
print(f"数据集形状: {original_data.shape}")
print(f"列名: {list(original_data.columns)}")
print("\n前5行数据:")
print(original_data.head())
print("\n数据类型:")
print(original_data.dtypes)
print("\n缺失值统计:")
print(original_data.isna().sum().sort_values(ascending=False))
```

