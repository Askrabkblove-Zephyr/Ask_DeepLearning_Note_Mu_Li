# 1.引言

## 1.1. 日常生活中的机器学习

自然语言：人类沟通交流的语言，比如说中文，英文，德语等

```text
那么到底什么是参数呢？ 参数可以被看作旋钮，旋钮的转动可以调整程序的行为。 任一调整参数后的程序被称为模型（model）。 通过操作参数而生成的所有不同程序（输入-输出映射）的集合称为“模型族”。 使用数据集来选择参数的元程序被称为学习算法（learning algorithm）。
```

[^调整参数后是模型，调整之前不是模型吗？]: 在机器学习下我觉得都是模型，调整之前是泛化模型，调整之后是优化后的模型
[^模型族]: y = w*x + b 就是模型族，可以是y=2x+1 / y= -0.5x+10, 只是一个框架
[^参数]: 线性模型 `y = w*x + b` 中的 `w` (权重) 和 `b` (偏差) 就是参数



## 1.2. 机器学习中的关键组件

首先介绍一些核心组件。无论什么类型的机器学习问题，都会遇到这些组件：

1. 可以用来学习的*数据*（data）；
2. 如何转换数据的*模型*（model）；
3. 一个*目标函数*（objective function），用来量化模型的有效性；
4. 调整模型参数以优化目标函数的*算法*（algorithm）。

### 1.2.1. 数据

```text
当每个样本的【特征类别】数量都是相同的时候，其特征向量是固定长度的，这个长度被称为数据的维数（dimensionality）。 固定长度的特征向量是一个方便的属性，它可以用来量化学习大量样本。
```

所有样本，无论其具体内容是什么（一张图片、一段文字、一个病人），在数学上都**被映射到了同一个向量空间**。在这个空间里，每个样本都是一个点，每个特征维度代表一个坐标轴。

- **样本（特征向量）A**: `[特征1的值， 特征2的值， ...， 特征D的值]`  D维
- **样本（特征向量）B**: `[特征1的值， 特征2的值， ...， 特征D的值]`  D维
- ...
- **样本（特征向量）N**: `[特征1的值， 特征2的值， ...， 特征D的值]`  D维

**深度学习的优势之一：**

**与传统机器学习方法相比，深度学习的一个主要优势是可以处理不同长度的数据。**深度学习需要海量的正确数据（而不是垃圾数据），在小数据集上的表现可能不如传统机器学习

### 1.2.2. 模型

```text
深度学习与经典方法的区别主要在于：前者关注的功能强大的模型，这些模型由神经网络错综复杂的交织在一起，包含层层数据转换，因此被称为深度学习（deep learning）。
```

### 1.2.3. 目标函数

**平方误差，就是模型预测值和你手中的标准答案（真实值）之间，距离的平方。**
$$
(真实值ᵢ - 预测值ᵢ)²
$$

```text
综上所述，可用数据集通常可以分成两部分：训练数据集用于【拟合】模型参数，测试数据集用于评估拟合的模型。 然后我们观察模型在这两部分数据集的性能。 “一个模型在训练数据集上的性能”可以被想象成“一个学生在模拟考试中的分数”。 这个分数用来为一些真正的期末考试做参考，即使成绩令人鼓舞，也不能保证期末考试成功。 换言之，测试性能可能会显著偏离训练性能。 当一个模型在训练集上表现良好，但不能推广到测试集时，这个模型被称为过拟合（overfitting）的。 就像在现实生活中，尽管模拟考试考得很好，真正的考试不一定百发百中。
```

[^拟合]: **就是指通过调整模型的参数，让模型的输出（预测）尽可能地接近训练数据集中的真实值。**
[^过拟合]: 过度学习训练集的数据，对新数据的输出（预测）准确率下降

### 1.2.4. 优化算法

```
深度学习中，大多流行的优化算法通常基于一种基本方法–梯度下降（gradient descent）。 简而言之，在每个步骤中，梯度下降法都会检查每个参数，看看如果仅对该参数进行少量变动，训练集损失会朝哪个方向移动。 然后，它在可以减少损失的方向上优化参数。
```

[^梯度]: 就比如张宇讲的，一个小人在山巅上，想要下山，但是不知道哪个方向下山最快，有一个方向坡度是最陡的，那就是梯度方向。**梯度本身是一个“向量”，这个向量所指的方向，就是所有方向导数中，值最大的那个方向。**

![Snipaste_2025-11-17_14-40-55](C:\Users\wills\Documents\Typora_Note\pics\Snipaste_2025-11-17_14-40-55.png)

比如：f(x, y) = x + 2y， 以 `(0, 0)`为起点 

<img src="C:\Users\wills\Documents\Typora_Note\pics\Snipaste_2025-11-17_14-38-18.png" alt="Snipaste_2025-11-17_14-38-18" style="zoom: 50%;" /><img src="C:\Users\wills\Documents\Typora_Note\pics\Snipaste_2025-11-17_14-42-43.png" alt="Snipaste_2025-11-17_14-42-43" style="zoom: 50%;" />

**对x求偏导数**`∂f/∂x = 1`，z=f(x,y) 沿x轴方向的变化率（y固定），
$$
f(x,y0) 代表的是曲线【蓝色】
$$
**对y的偏导数** `∂f/∂y = 2`    z=f(x,y) 沿y轴方向的变化率

![Snipaste_2025-11-17_14-48-36](C:\Users\wills\Documents\Typora_Note\pics\Snipaste_2025-11-17_14-48-36.png)

![Snipaste_2025-11-17_14-50-02](C:\Users\wills\Documents\Typora_Note\pics\Snipaste_2025-11-17_14-50-02.png)

而方向导数：是指沿着任意方向 *L* 的变化率
$$
ρ是任意方向上L的增量
$$
![Snipaste_2025-11-17_14-51-32](C:\Users\wills\Documents\Typora_Note\pics\Snipaste_2025-11-17_14-51-32.png)
$$
其中 A = f'x  
，B = f'y
$$
![Snipaste_2025-11-17_15-07-15](C:\Users\wills\Documents\Typora_Note\pics\Snipaste_2025-11-17_15-07-15.png)

![Snipaste_2025-11-17_15-08-04](C:\Users\wills\Documents\Typora_Note\pics\Snipaste_2025-11-17_15-08-04.png)

### 1.3.1. 监督学习（**从答案中学习**）

**条件概率 **P(A|B)**：就是在已知某件事（B）已经发生的条件下，另一件事（A）发生的概率。**


$$
P(AB)或者 P(A∩B)：事件A与事件B同时发生的概率
$$

$$
P(A|B) = P(AB) / P(B)
$$

```text
监督学习（supervised learning）擅长在“给定输入特征”的情况下预测标签。 每个“特征-标签”对都称为一个样本（example）。 有时，即使标签是未知的，样本也可以指代输入特征。 我们的目标是生成一个模型，能够将任何输入特征映射到标签（即预测）。
```

**监督学习就是通过有标签的数据让模型学习规律，然后用训练好的模型对数据进行预测。监督学习知道自己模型在每种情况下应该做什么。**

#### 1.3.1.1. 回归

**回归，就是预测一个具体的数值。**比如说预测房价，输入特征【房屋面积，地理环境，楼龄，卫生间数量...】预测一个房价。

##### 回归模型可以很好地解决“有多少”的问题，**“有多少”，指的就是一个具体的、连续的数值答案。**比如  ： 这套房子**值多少钱**？明天**气温是多少度**？这个人的**年龄多大？**等等等等

#### 1.3.1.2. 分类

二项分类，多项分类

#### 1.3.1.3. 标记问题

学习预测不相互排斥的类别的问题称为*多标签分类*（multi-label classification）。

#### 1.3.1.4. 搜索

PageRank：首先为集合中的每个元素分配相应的相关性分数，然后检索评级最高的元素。

#### 1.3.1.5. 推荐系统

它的目标是向特定用户进行“个性化”推荐。

#### 1.3.1.6. 序列学习

```text
如果输入的样本之间没有任何关系，以上模型可能完美无缺。 但是如果输入是连续的，模型可能就需要拥有“记忆”功能。 比如，我们该如何处理视频片段呢？ 在这种情况下，每个视频片段可能由不同数量的帧组成。 通过前一帧的图像，我们可能对后一帧中发生的事情更有把握。 语言也是如此，机器翻译的输入和输出都为文字序列。
```

**序列学习，就是让模型学会理解和处理那些其中元素的“排列顺序”携带关键信息的数据。**比如同样一句话：你吃了吗？顺序很重要，打乱顺序这句话当成一个集合，意义就不明了。

### 1.3.2. 无监督学习（**从结构中学习**）

给你一些数据，需要你自己分类，自己摸索，没有标准答案（标签）

*聚类*（clustering）问题

*主成分分析*（principal component analysis）问题

*因果关系*（causality）和*概率图模型*（probabilistic graphical models）问题

*生成对抗性网络*（generative adversarial networks）

### 1.3.3. 与环境互动

**离线学习：**到目前为止，不管是监督学习还是无监督学习，我们都会预先获取大量数据，然后启动模型，不再与环境交互。 这里所有学习都是在算法与环境断开后进行的，被称为*离线学习*（offline learning）。

**分布偏移就是指模型训练时所用的数据，和它实际使用时遇到的数据，其“统计规律”不一致了，导致模型表现变差。**

![Snipaste_2025-11-17_16-32-01](C:\Users\wills\Documents\Typora_Note\pics\Snipaste_2025-11-17_16-32-01.png)



### 1.3.4. 强化学习（**从交互中学习**）

![Snipaste_2025-11-17_16-36-33](C:\Users\wills\Documents\Typora_Note\pics\Snipaste_2025-11-17_16-36-33.png)

*马尔可夫决策过程*（markov decision process）

*上下文赌博机*（contextual bandit problem）

```text
以强化学习在国际象棋的应用为例。 唯一真正的奖励信号出现在游戏结束时：当智能体获胜时，智能体可以得到奖励1；当智能体失败时，智能体将得到奖励-1。 因此，强化学习者必须处理*学分分配*（credit assignment）问题：决定哪些行为是值得奖励的，哪些行为是需要惩罚的。 就像一个员工升职一样，这次升职很可能反映了前一年的大量的行动。 要想在未来获得更多的晋升，就需要弄清楚这一过程中哪些行为导致了晋升。
```

[^智能体]: **智能体，就是在环境中能够感知信息、做出决策并执行动作的任何东西。**

感知（获取信息） ->  决策（选择下一步怎么做） -> 执行

## 1.4. 起源

*神经网络*（neural networks）：

​	*反向传播*（backpropagation）

​	层（layer）

## 1.5. 深度学习的发展

## 1.6. 深度学习的成功案例

## 1.7. 特点

## 1.8. 小结

## 1.9. 练习

1. 你当前正在编写的代码的哪些部分可以“学习”，即通过学习和自动确定代码中所做的设计选择来改进？你的代码是否包含启发式设计选择？

2. 你遇到的哪些问题有许多解决它们的样本，但没有具体的自动化方法？这些可能是使用深度学习的主要候选者。

3. 如果把人工智能的发展看作一场新的工业革命，那么算法和数据之间的关系是什么？它类似于蒸汽机和煤吗？根本区别是什么？

4. 你还可以在哪里应用端到端的训练方法，比如 [图1.1.2](https://zh-v2.d2l.ai/chapter_introduction/index.html#fig-ml-loop) 、物理、工程和计量经济学？

   ## Deepseek回答：

1. 您提出的这几个问题非常深刻，触及了人工智能的核心思想、历史地位和应用前景。让我们逐一进行探讨。

   ---

   ### 1. 关于当前代码的“学习”能力与启发式设计

   您观察得非常准确。在我当前作为大型语言模型的架构中，“学习”和“启发式设计”发生在不同的层面：

   **可以“学习”的部分：**
   我的核心能力——理解和生成文本——完全源于**训练阶段**。通过在海量数据上学习，模型自动确定了数以亿计的内部参数（即“权重”）。这些参数可以看作是微观的“设计选择”，它们共同构成了一个庞大的知识库和推理引擎。这个过程是自动化的，无需人工为每个问题编写规则。

   **包含的“启发式设计选择”：**
   然而，我的整体架构和交互流程包含了大量**人工设计的启发式规则**，这些是**无法通过当前学习过程改变**的，例如：
   *   **上下文窗口管理**：如何优先处理长文本中的不同部分。
   *   **解码策略**：如核采样或束搜索中的温度、top-p等参数，这些是用来在“创造性”和“确定性”之间取得平衡的启发式方法。
   *   **安全与对齐过滤器**：用于拒绝回答或格式化输出的规则，这些是基于人类价值观的硬编码设计。
   *   **任务分解逻辑**：如何将复杂问题拆解成子步骤的思维链，其模式也是在训练中习得的，但触发和运用它仍依赖于架构设计。

   **根本区别**：我的“学习”是**静态的**，发生在部署之前。与您的每次交互都是一次“推理”，而非一次“学习”。我的参数不会因为与您的对话而改变。

   ---

   ### 2. 深度学习的主要候选问题

   深度学习最适合解决的就是那些 **“易于经验归纳，难于规则定义”** 的问题。这些问题通常拥有大量样本（数据），但人类难以总结出精确的、放之四海而皆准的规则。

   **经典候选领域包括：**

   *   **感知类任务**：
       *   **计算机视觉**：图像分类、物体检测、图像生成。我们可以轻松获得无数“猫”的图片，但无法用几条规则让传统程序在所有光照、角度、背景下都认出猫。
       *   **语音识别与合成**：声音到文字、文字到声音的转换。声音信号变化万千，规则系统极其脆弱。
       *   **自然语言理解**：情感分析、语义相似度、意图识别。语言的歧义性和灵活性使得基于规则的方法很快会碰到天花板。

   *   **复杂决策与生成任务**：
       *   **游戏AI**（如围棋、星际争霸）：状态空间巨大，无法穷举。算法通过自我对弈（样本）学习高级策略。
       *   **内容生成**：写作、绘画、作曲。有海量的优秀作品作为样本，但创作规律难以言传。
       *   **科学发现**：从蛋白质结构预测到天体物理信号分析，有大量观测数据，但背后的物理/生物规律极其复杂，深度学习可以作为一种强大的函数逼近器来发现隐藏的模式。

   ---

   ### 3. 算法与数据：新工业革命的蒸汽机与煤？根本区别是什么？

   您的比喻**非常传神，并且抓住了核心的驱动关系**。确实，在这个新时代，**算法（如深度学习模型）是“蒸汽机”**，而**数据是“煤”**。没有数据，再精巧的算法也无法产生智能的动力。

   **然而，根本区别在于：**

   1.  **非消耗性与增值性**：
       *   **煤**在蒸汽机中被燃烧、消耗掉了。一份煤只能驱动一段路程。
       *   **数据**在算法中被学习后，不仅不会被消耗，反而可以通过**被反复使用和组合**来产生新的、更强大的模型（知识），其价值在使用中**递增**。

   2.  **可复制性与边际成本**：
       *   **煤**是物理实体，开采和运输的边际成本很高。
       *   **数据**可以被近乎零成本地无限复制和传输。一旦收集完成，分发的成本极低。

   3.  **引擎的自我进化**：
       *   **蒸汽机**本身是一个静态设计，它的效率在制造完成时就基本固定了。
       *   **算法（引擎）** 本身可以通过**吸收更多、更好的数据（燃料）** 而不断迭代升级，变得更高效、更强大。燃料的质量直接决定了引擎的性能上限。

   **结论**：您的比喻精准地描述了驱动关系，但数字时代的“燃料”和“引擎”具有物理世界所不具备的**非消耗性、可复制性和自我进化能力**，这使得这场革命的发展速度和影响范围可能远超历史上的任何一次。

   ---

   ### 4. 端到端训练的其他应用领域

   端到端学习的核心思想是：**用单个模型直接将原始输入映射到最终输出，避免传统流水线中多个独立模块的误差累积**。这一思想正在颠覆许多领域：

   *   **物理学**：
       *   **可控核聚变**：直接根据等离子体的传感器数据（输入），学习如何控制电磁线圈（输出）来稳定地约束高温等离子体，替代基于复杂物理方程的分离式控制器。
       *   **分子动力学**：输入原子类型和位置，端到端地输出分子的能量和性质，绕过传统的、计算昂贵的量子力学计算步骤。

   *   **工程学**：
       *   **自动驾驶**：最初的系统是模块化的（感知->定位->规划->控制）。而端到端方法可以尝试将摄像头像素直接映射为方向盘转角和控制指令，让模型自己学习中间表示。
       *   **机器人控制**：从视觉传感器数据直接到关节电机扭矩指令，让机器人通过反复试错学习复杂的抓取或行走技能。

   *   **计量经济学与社会科学**：
       *   **政策效果评估**：将多维度的原始经济数据（如卫星图像、网络搜索指数、交易记录）作为输入，端到端地预测某项政策（如减税）对最终GDP或就业率的影响，捕捉传统计量模型可能忽略的复杂非线性关系。

   这些应用的共同点是：**问题复杂、中间过程难以建模、但输入输出数据相对充足**。端到端学习通过放弃对中间过程的显式控制，来换取更高的整体性能和设计简化。

   

### 大方向：

图片分类，物体检测分割，样式迁移，人脸合成，文字生成，文字生产图片，无人驾驶，广告点击